{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING ON A SINGLE NEWS ARTICLE\n",
    "\n",
    "(without using any libraries)\n",
    "\n",
    "please note - the data obtained from the directory below is raw data from the original 20_newsgroups data, it is not the one present in sklearn.datasets hence it needs different preprocessing as compared to the sklearn one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "fdata = codecs.open('20_newsgroups/alt.atheism/49960', \"r\",encoding='utf-8', errors='ignore') \n",
    "file_data = fdata.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the header lines which are separated by newline\n",
    "# we keep the subject line which will help us dertermine the type of news\n",
    "\n",
    "file_data = file_data.split(\"\\n\")\n",
    "words = []\n",
    "for word in file_data:\n",
    "    if(':' not in word and '@' not in word):\n",
    "        words.append(word)\n",
    "    elif(word.startswith(\"Subject\")):\n",
    "        words.append(word)\n",
    "#print(words)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n",
      "['subject', 'altatheism', 'faq', 'atheist', 'resources', 'atheist', 'resources', 'addresses', 'atheist', 'organizations', 'usa', 'freedom', 'religion', 'foundation', 'darwin', 'fish', 'bumper', 'stickers', 'assorted', 'atheist', 'paraphernalia', 'available', 'freedom', 'religion', 'foundation', 'us', 'evolution', 'designs', 'evolution', 'designs', 'sell', 'darwin', 'fish', 'fish', 'symbol', 'like', 'ones', 'christians', 'stick', 'cars', 'feet', 'word', 'darwin', 'written', 'inside', 'deluxe', 'moulded', 'plastic', 'fish', 'postpaid', 'us', 'ca', 'people', 'san', 'francisco', 'bay', 'area', 'get', 'darwin', 'fish', 'lynn', 'gold', 'price', 'per', 'fish', 'american', 'atheist', 'press', 'aap', 'publish', 'various', 'atheist', 'books', 'critiques', 'bible', 'lists', 'bible', 'handbook', 'wp', 'ball', 'gw', 'foote', 'american', 'atheist', 'press', 'pp', 'isbn', 'edition', 'bible', 'contradictions', 'contradicts', 'aap', 'based', 'king', 'james', 'version', 'bible', 'prometheus', 'books', 'sell']\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESSING\n",
    "# now we separate each word and clean the rest of the document \n",
    "words = \" \".join(words)\n",
    "words = words.lower()\n",
    "words = words.split()\n",
    "text = []\n",
    "for i in words:\n",
    "    new_str = re.sub('[^ a-zA-Z0-9]', '', i)\n",
    "    text.append(new_str)\n",
    "    \n",
    "stop = stopwords.words('english')\n",
    "words_2 = [i for i in text if not i in stop]\n",
    "# REMOVED STOP WORDS\n",
    "words = [i for i in words_2 if str.isalpha(i)]\n",
    "\n",
    "print(len(words))\n",
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, freq = np.unique(words, return_counts=True)\n",
    "#print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647\n"
     ]
    }
   ],
   "source": [
    "print(len(unique))\n",
    "# 822->753 on converting to lower \n",
    "# around 50 words difference on removing special characters attatched before and after each word and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = {}\n",
    "for i in range(len(unique)):\n",
    "    x = freq[i]\n",
    "    freq_dict[unique[i]] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict_temp = freq_dict.copy()    \n",
    "for i in freq_dict_temp:\n",
    "    if(freq_dict_temp[i]<2):        \n",
    "        del freq_dict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n",
      "['addresses', 'freedom', 'foundation', 'available', 'freedom', 'foundation', 'us', 'evolution', 'designs', 'evolution', 'designs', 'sell', 'christians', 'written', 'us', 'area', 'aap', 'various', 'aap', 'based', 'version', 'sell', 'including', 'see', 'buffalo', 'ny', 'black', 'black', 'freethought', 'buffalo', 'ny', 'association', 'national', 'association', 'national', 'ibka', 'ev', 'internationaler', 'konfessionslosen', 'und', 'atheisten', 'berlin', 'und', 'und', 'atheisten', 'ibka', 'ev', 'berlin', 'internationaler', 'konfessionslosen', 'santa', 'short', 'story', 'santa', 'characters', 'dead', 'well', 'jr', 'leibowitz', 'one', 'post', 'atomic', 'doomsday', 'leibowitz', 'post', 'atomic', 'doomsday', 'set', 'philip', 'k', 'philip', 'k', 'wrote', 'philosophical', 'short', 'stories', 'stories', 'times', 'wrote', 'wrote', 'rather', 'although', 'pothealer', 'deity', 'earth', 'deity', 'faith', 'pothealer', 'brain', 'divine', 'characters', 'divine', 'earth', 'dead', 'brain', 'tale', 'story', 'based', 'us', 'congress', 'fundamentalists', 'set', 'right', 'right', 'used', 'used', 'tale', 'various', 'work', 'different', 'one', 'version', 'de', 'rosa', 'although', 'de', 'rosa', 'contains', 'appendix', 'tendentious', 'area', 'belief', 'hardcover', 'available', 'university', 'incoherent', 'creed', 'university', 'unbelief', 'way', 'unbelief', 'worldview', 'religious', 'creed', 'rather', 'idea', 'belief', 'hardcover', 'quotations', 'different', 'present', 'worldview', 'way', 'various', 'idea', 'number', 'quotations', 'revised', 'oxford', 'volume', 'faith', 'work', 'tendentious', 'miracle', 'revised', 'appendix', 'incoherent', 'mackie', 'mackie', 'miracle', 'oxford', 'volume', 'contains', 'classical', 'philosophical', 'positions', 'classical', 'addresses', 'positions', 'well', 'written', 'religious', 'times', 'present', 'christians', 'congress', 'number', 'jr', 'see', 'anthology', 'anthology', 'including', 'freethought', 'fundamentalists']\n"
     ]
    }
   ],
   "source": [
    "final_doc = []\n",
    "for i in words:\n",
    "    if(i in freq_dict):\n",
    "        final_doc.append(i)\n",
    "\n",
    "print(len(final_doc))\n",
    "# this is the final document which forms 1 training example\n",
    "print(final_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
